# Отчет

Данная работа демонстрирует применение паттерна проектирования "Шаблонный метод" (Template Method) в контексте работы с алгоритмами машинного обучения. Проект реализует визуализацию процесса обучения линейной регрессии с использованием стохастического градиентного спуска (SGD) как с применением Batch Normalization (BN), так и без него.

## Паттерн "Шаблонный метод" (Template Method)

Паттерн "Шаблонный метод" — это поведенческий паттерн проектирования, который определяет скелет алгоритма в базовом классе, позволяя подклассам переопределять отдельные шаги алгоритма без изменения его структуры. Он относится к категории поведенческих паттернов, так как определяет способ организации взаимодействия между классами и объектами.

### Основные компоненты паттерна "Шаблонный метод":

1. **Абстрактный класс** — определяет абстрактные примитивные операции, конкретные примитивные операции, а также шаблонный метод, который использует эти операции для реализации алгоритма.
2. **Конкретные классы** — реализуют примитивные абстрактные операции, переопределяя их для выполнения специфических шагов алгоритма.

### Зачем нужен паттерн "Шаблонный метод" в данном проекте?

В контексте машинного обучения часто имеются схожие алгоритмы, которые отличаются только в некоторых деталях реализации. Паттерн "Шаблонный метод" идеально подходит для этой задачи по ряду причин:

1. **Устранение дублирования кода** — общая логика обучения моделей вынесена в базовый класс, а специфические детали реализованы в подклассах.
2. **Разделение ответственности** — базовый класс определяет структуру алгоритма, а подклассы предоставляют конкретную реализацию отдельных шагов.
3. **Гибкость и расширяемость** — легко добавлять новые варианты алгоритмов, создавая новые подклассы без изменения существующего кода.
4. **Контроль над переопределением** — базовый класс может определять, какие шаги алгоритма могут быть переопределены, а какие должны остаться неизменными (с помощью final методов или hook-методов).
5. **Инверсия управления** — подклассы вызываются базовым классом, а не наоборот, что обеспечивает более стабильную архитектуру.

### Как паттерн "Шаблонный метод" реализован в проекте?

В проекте паттерн "Шаблонный метод" реализован в модуле trainer.py и состоит из следующих компонентов:

1. **Абстрактный базовый класс** (`AbstractTrainer`) — определяет общую структуру алгоритма обучения:
   - `train()` — шаблонный метод, который определяет последовательность шагов обучения
   - `reset_epoch_counter()` — абстрактный метод для сброса счетчика эпох
   - `initialize_params()` — абстрактный метод для инициализации параметров модели
   - `prepare_data_iterator()` — абстрактный метод для подготовки итератора данных
   - `perform_epoch()` — абстрактный метод для выполнения одной эпохи обучения
   - `update_callback()` — абстрактный метод для обновления обратного вызова
   - `save_training_results()` — абстрактный метод для сохранения результатов обучения

2. **Конкретная реализация без BN** (`SGDTrainerNoBN`) — реализует алгоритм обучения без использования Batch Normalization:
   - Переопределяет `reset_epoch_counter()` — сбрасывает счетчик эпох
   - Переопределяет `initialize_params()` — для обучения без BN не требуются дополнительные параметры
   - Переопределяет `prepare_data_iterator()` — подготавливает данные для обучения без батчей
   - Переопределяет `perform_epoch()` — выполняет обучение без нормализации
   - Переопределяет `update_callback()` — обновляет UI через callback
   - Переопределяет `save_training_results()` — сохраняет финальные веса и историю

3. **Конкретная реализация с BN** (`SGDTrainerWithBN`) — реализует алгоритм обучения с использованием Batch Normalization:
   - Переопределяет `reset_epoch_counter()` — сбрасывает счетчик эпох
   - Переопределяет `initialize_params()` — инициализирует параметры gamma и beta для BN
   - Переопределяет `prepare_data_iterator()` — подготавливает итератор по мини-батчам
   - Переопределяет `perform_epoch()` — выполняет обучение с нормализацией
   - Переопределяет `update_callback()` — обновляет UI через callback с информацией о BN
   - Переопределяет `save_training_results()` — сохраняет финальные веса и историю

На рисунке 1 изображена архитектура приложения с использованием паттерна "Шаблонный метод".

<img src="diagrams/mermaid-diagram.png" alt="Архитектура приложения с использованием паттерна 'Шаблонный метод'" width="100%" />

<center>рис.1 - архитектура приложения с использованием паттерна "Шаблонный метод" </center> 

## Как паттерн "Шаблонный метод" используется в проекте

Паттерн "Шаблонный метод" играет ключевую роль в организации процесса обучения:

1. **Единая структура алгоритма обучения**:
   ```python
   # В абстрактном классе AbstractTrainer
   def train(self, callback=None):
       """Шаблонный метод, определяющий общую структуру алгоритма обучения"""
       self.callback = callback
       self.training_in_progress = True
       self.reset_epoch_counter()
       
       w = self.initial_w.copy()
       w_history = [w.flatten()]
       
       # Инициализация дополнительных параметров
       params = self.initialize_params()
       
       # Подготовка данных для обучения
       data_iterator = self.prepare_data_iterator()
       
       for epoch in range(self.n_epochs):
           self.current_epoch = epoch + 1
           
           # Выполнение одной эпохи обучения
           w, w_history, params = self.perform_epoch(w, w_history, params, data_iterator)
           
           # Обратный вызов для обновления UI
           if callback and epoch % 1 == 0:
               self.update_callback()
       
       # Сохранение результатов обучения
       self.save_training_results(w, np.array(w_history))
       self.training_in_progress = False
       
       return w, np.array(w_history)
   ```
   
   Абстрактный класс определяет общую структуру алгоритма обучения, а конкретные подклассы реализуют специфические шаги этого алгоритма.

2. **Разделение ответственности**:
   - Абстрактный класс `AbstractTrainer` отвечает за общую логику процесса обучения
   - `SGDTrainerNoBN` отвечает за специфику обучения без Batch Normalization
   - `SGDTrainerWithBN` отвечает за специфику обучения с Batch Normalization
   
   Это обеспечивает хорошую модульность и облегчает поддержку и тестирование кода.

3. **Пример реализации методов в подклассах**:
   ```python
   # В классе SGDTrainerNoBN
   def perform_epoch(self, w, w_history, params, data_iterator):
       """Выполняет одну эпоху обучения без BN"""
       X_full, y_full = data_iterator[0]
       
       grad_w = compute_batch_gradient_no_bn(X_full, y_full, w)
       w = w - self.lr_w * grad_w
       w_history.append(w.flatten())
       
       return w, w_history, params
   
   # В классе SGDTrainerWithBN
   def perform_epoch(self, w, w_history, params, data_iterator):
       """Выполняет одну эпоху обучения с BN"""
       gamma = params['gamma']
       beta = params['beta']
       
       for X_batch, y_batch in data_iterator:
           if len(y_batch) == 0:
               continue
           
           grad_w, grad_gamma, grad_beta, _ = compute_bn_forward_and_grad(
               X_batch, y_batch, w, gamma, beta, self.epsilon_bn, compute_grads=True
           )
           
           if not self.freeze_bn_params:
               gamma = gamma - self.lr_bn * grad_gamma
               beta = beta - self.lr_bn * grad_beta
           
           w = w - self.lr_w * grad_w
           w_history.append(w.flatten())
       
       params['gamma'] = gamma
       params['beta'] = beta
       
       return w, w_history, params
   ```
   
   Каждый подкласс реализует специфические детали своего алгоритма, но общая последовательность шагов определена в базовом классе.

4. **Различия в подготовке данных**:
   ```python
   # В классе SGDTrainerNoBN
   def prepare_data_iterator(self):
       """Для обучения без BN используется весь датасет сразу"""
       return [(self.X, self.y)]
   
   # В классе SGDTrainerWithBN
   def prepare_data_iterator(self):
       """Подготавливает итератор по мини-батчам данных"""
       return DataLoader(self.X, self.y, self.batch_size, shuffle=True)
   ```
   
   Базовый класс делегирует конкретным подклассам решение о том, как подготавливать данные, а сам использует готовый итератор.

## Заключение

Паттерн "Шаблонный метод" в данном проекте эффективно решает задачу структурирования различных алгоритмов обучения с сохранением их общей логики. Он обеспечивает чистое разделение ответственности между компонентами, позволяет избежать дублирования кода и предоставляет гибкую основу для добавления новых вариантов алгоритмов.

Проект демонстрирует, как можно применять классические паттерны проектирования в современных задачах машинного обучения, обеспечивая хорошую структуру кода и возможности для расширения. Благодаря использованию паттерна "Шаблонный метод", реализация различных вариантов алгоритма (с BN и без BN) стала более организованной и поддерживаемой.